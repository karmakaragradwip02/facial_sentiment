{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'e:\\\\Deep Learning\\\\pytorch\\\\facial_emotion_prediction'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.chdir('../')\n",
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = 'artifacts/data_preparation/train'\n",
    "val_path = \"artifacts/data_preparation/val\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import glob\n",
    "import torch.nn as nn\n",
    "from torchvision.transforms import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim import Adam\n",
    "from torch.autograd import Variable\n",
    "import torchvision\n",
    "import pathlib\n",
    "import mlflow\n",
    "import mlflow.pytorch\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_transforms():\n",
    "    transformer = transforms.Compose([\n",
    "        transforms.Resize((48, 48)),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),  # 0-250 to 0-1 numpy to tensors\n",
    "        transforms.Normalize([0.5, 0.5, 0.5],\n",
    "                             [0.5, 0.5, 0.5])\n",
    "    ])\n",
    "    return transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_loader(train_path, test_path, transformer):\n",
    "    train_loader = DataLoader(\n",
    "        torchvision.datasets.ImageFolder(train_path, transform=transformer),\n",
    "        batch_size=16, shuffle=True\n",
    "    )\n",
    "    test_loader = DataLoader(\n",
    "        torchvision.datasets.ImageFolder(test_path, transform=transformer),\n",
    "        batch_size=16, shuffle=True\n",
    "    )\n",
    "    return train_loader, test_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def class_name(train_path):\n",
    "    root = pathlib.Path(train_path)\n",
    "    classes = sorted([j.name.split('/')[-1] for j in root.iterdir()])\n",
    "    return classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_count(train_path, test_path):\n",
    "    train_count = len(glob.glob(train_path + '/**/*.jpg'))\n",
    "    test_count = len(glob.glob(test_path + '/**/*.jpg'))\n",
    "    return train_count, test_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['angry', 'disgust', 'fear', 'happy', 'neutral', 'sad', 'surprise']\n"
     ]
    }
   ],
   "source": [
    "transformer = define_transforms()\n",
    "train_loader, test_loader = data_loader(train_path, val_path, transformer)\n",
    "classes = class_name(train_path)\n",
    "print(classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_count, val_count = train_test_count(train_path, val_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25117 , 7178\n"
     ]
    }
   ],
   "source": [
    "print(train_count, \",\", val_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of channels: 1\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "img = Image.open('artifacts/data_preparation/train/disgust/416.jpg')\n",
    "img_channels = len(img.getbands())  \n",
    "print(\"Number of channels:\", img_channels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 32, 48, 48]             896\n",
      "       BatchNorm2d-2           [-1, 32, 48, 48]              64\n",
      "              ReLU-3           [-1, 32, 48, 48]               0\n",
      "         MaxPool2d-4           [-1, 32, 24, 24]               0\n",
      "            Conv2d-5           [-1, 64, 24, 24]          18,496\n",
      "       BatchNorm2d-6           [-1, 64, 24, 24]             128\n",
      "              ReLU-7           [-1, 64, 24, 24]               0\n",
      "         MaxPool2d-8           [-1, 64, 12, 12]               0\n",
      "            Conv2d-9          [-1, 128, 12, 12]          73,856\n",
      "      BatchNorm2d-10          [-1, 128, 12, 12]             256\n",
      "             ReLU-11          [-1, 128, 12, 12]               0\n",
      "        MaxPool2d-12            [-1, 128, 6, 6]               0\n",
      "           Conv2d-13            [-1, 256, 6, 6]         295,168\n",
      "      BatchNorm2d-14            [-1, 256, 6, 6]             512\n",
      "             ReLU-15            [-1, 256, 6, 6]               0\n",
      "        MaxPool2d-16            [-1, 256, 3, 3]               0\n",
      "           Conv2d-17            [-1, 512, 3, 3]       1,180,160\n",
      "      BatchNorm2d-18            [-1, 512, 3, 3]           1,024\n",
      "             ReLU-19            [-1, 512, 3, 3]               0\n",
      "        MaxPool2d-20            [-1, 512, 1, 1]               0\n",
      "          Flatten-21                  [-1, 512]               0\n",
      "           Linear-22                 [-1, 1024]         525,312\n",
      "             ReLU-23                 [-1, 1024]               0\n",
      "          Dropout-24                 [-1, 1024]               0\n",
      "           Linear-25                  [-1, 512]         524,800\n",
      "             ReLU-26                  [-1, 512]               0\n",
      "          Dropout-27                  [-1, 512]               0\n",
      "           Linear-28                    [-1, 7]           3,591\n",
      "================================================================\n",
      "Total params: 2,624,263\n",
      "Trainable params: 2,624,263\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.03\n",
      "Forward/backward pass size (MB): 3.58\n",
      "Params size (MB): 10.01\n",
      "Estimated Total Size (MB): 13.61\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchsummary import summary\n",
    "\n",
    "def print_model_summary(model, input_size):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.to(device)\n",
    "    summary(model, input_size, device=str(device))\n",
    "\n",
    "def complex_model():\n",
    "    input_channels = 3  # Update to 3 for RGB images\n",
    "    img_size = [48, 48]\n",
    "\n",
    "    cnn = nn.Sequential(\n",
    "        # Convolutional Layer 1\n",
    "        nn.Conv2d(input_channels, 32, kernel_size=3, padding=1),\n",
    "        nn.BatchNorm2d(32),\n",
    "        nn.ReLU(),\n",
    "        nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "        \n",
    "        # Convolutional Layer 2\n",
    "        nn.Conv2d(32, 64, kernel_size=3, padding=1),\n",
    "        nn.BatchNorm2d(64),\n",
    "        nn.ReLU(),\n",
    "        nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "        \n",
    "        # Convolutional Layer 3\n",
    "        nn.Conv2d(64, 128, kernel_size=3, padding=1),\n",
    "        nn.BatchNorm2d(128),\n",
    "        nn.ReLU(),\n",
    "        nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "\n",
    "        # Additional Convolutional Layer 4\n",
    "        nn.Conv2d(128, 256, kernel_size=3, padding=1),\n",
    "        nn.BatchNorm2d(256),\n",
    "        nn.ReLU(),\n",
    "        nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "\n",
    "        # Additional Convolutional Layer 5\n",
    "        nn.Conv2d(256, 512, kernel_size=3, padding=1),\n",
    "        nn.BatchNorm2d(512),\n",
    "        nn.ReLU(),\n",
    "        nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "        \n",
    "        # Flatten and Fully Connected Layers\n",
    "        nn.Flatten(),\n",
    "        nn.Linear(512 * (img_size[0] // 32) * (img_size[1] // 32), 1024),\n",
    "        nn.ReLU(),\n",
    "        nn.Dropout(0.5),\n",
    "        nn.Linear(1024, 512),\n",
    "        nn.ReLU(),\n",
    "        nn.Dropout(0.5),\n",
    "        nn.Linear(512, 7)  # Output layer adjusted for 7 classes\n",
    "    )\n",
    "\n",
    "    print_model_summary(cnn, (input_channels, *img_size))\n",
    "    return cnn\n",
    "\n",
    "# Create the complex model\n",
    "model = complex_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0\n",
      "Epoch: 0 Train Loss: 1.5813 Train Accuracy: 0.3724 Test Accuracy: 0.4579\n"
     ]
    }
   ],
   "source": [
    "optimizer = Adam(model.parameters(), lr=0.001, weight_decay=0.0001)\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "num_epochs = 1\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    print(\"Epoch:\", epoch)\n",
    "    model.train()\n",
    "    train_accuracy = 0.0\n",
    "    train_loss = 0.0\n",
    "\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        if torch.cuda.is_available():\n",
    "            images = images.cuda()\n",
    "            labels = labels.cuda()\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = model(images)\n",
    "        loss = loss_function(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item() * images.size(0)\n",
    "        _, prediction = torch.max(outputs.data, 1)\n",
    "        train_accuracy += int(torch.sum(prediction == labels.data))\n",
    "\n",
    "    train_accuracy = train_accuracy / train_count\n",
    "    train_loss = train_loss / train_count\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    test_accuracy = 0.0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_loader:\n",
    "            if torch.cuda.is_available():\n",
    "                images = images.cuda()\n",
    "                labels = labels.cuda()\n",
    "\n",
    "            outputs = model(images)\n",
    "            _, prediction = torch.max(outputs.data, 1)\n",
    "            test_accuracy += int(torch.sum(prediction == labels.data))\n",
    "\n",
    "    test_accuracy = test_accuracy / val_count\n",
    "\n",
    "    print(f'Epoch: {epoch} Train Loss: {train_loss:.4f} Train Accuracy: {train_accuracy:.4f} Test Accuracy: {test_accuracy:.4f}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "intel_img",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
